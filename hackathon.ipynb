{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWC2CjNzVeX2sYJh24bmw1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saqlainkazi690/Projects/blob/main/hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azS_U1aMHknt",
        "outputId": "2d4c4b22-e2e4-4e7f-c88a-1143f56234dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: import google drive'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "UxRlkh7PHz6o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "paired_dir = '/content/drive/MyDrive/EUVP Dataset/Paired'\n",
        "\n",
        "\n",
        "def collect_image_paths(directory):\n",
        "    poor_images = []\n",
        "    enhanced_images = []\n",
        "    validation_images = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "\n",
        "            if 'trainA' in root and file.endswith('.jpg'):\n",
        "                poor_images.append(os.path.join(root, file))\n",
        "\n",
        "            elif 'trainB' in root and file.endswith('.jpg'):\n",
        "                enhanced_images.append(os.path.join(root, file))\n",
        "\n",
        "            elif 'validation' in root and file.endswith('.jpg'):\n",
        "                validation_images.append(os.path.join(root, file))\n",
        "\n",
        "    return poor_images, enhanced_images, validation_images\n",
        "\n",
        "dark_poor, dark_enhanced, dark_validation = collect_image_paths(os.path.join(paired_dir, 'underwater_dark'))\n",
        "\n",
        "\n",
        "imagenet_poor, imagenet_enhanced, imagenet_validation = collect_image_paths(os.path.join(paired_dir, 'underwater_imagenet'))\n",
        "\n",
        "\n",
        "scenes_poor, scenes_enhanced, scenes_validation = collect_image_paths(os.path.join(paired_dir, 'underwater_scenes'))\n",
        "\n",
        "poor_images = dark_poor + imagenet_poor + scenes_poor\n",
        "enhanced_images = dark_enhanced + imagenet_enhanced + scenes_enhanced\n",
        "validation_list = dark_validation + imagenet_validation + scenes_validation\n",
        "\n",
        "print(\"Number of poor images:\", len(poor_images))\n",
        "print(\"Number of enhanced images:\", len(enhanced_images))\n",
        "print(\"Number of validation images:\", len(validation_list))\n",
        "print(poor_images[0:5])\n",
        "print(enhanced_images[0:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Fvqig4H2eR",
        "outputId": "a92f160d-6edc-4cde-ed74-47de8a36dbbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of poor images: 9020\n",
            "Number of enhanced images: 9020\n",
            "Number of validation images: 1732\n",
            "['/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainA/269038_00006117.jpg', '/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainA/270258_scuba_phi_phi_791.jpg', '/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainA/267852_00036420.jpg', '/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainA/272708_00014881.jpg', '/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainA/272507_00000748.jpg']\n",
            "['/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainB/267852_00036420.jpg', '/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainB/272708_00014881.jpg', '/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainB/270258_scuba_phi_phi_791.jpg', '/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainB/269038_00006117.jpg', '/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainB/272507_00000748.jpg', '/content/drive/MyDrive/EUVP Dataset/Paired/underwater_dark/trainB/269281_00035240.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i have two lists one of poor images paths and one of enhanced images paths i need to train a conditional gan model to compress poor images and generate enhanced images after compression and finally get the mse value between the original and generated image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "poor_images_data = []\n",
        "enhanced_images_data = []\n",
        "for image_path in poor_images:\n",
        "    image_data = tf.io.read_file(image_path)\n",
        "    image_data = tf.image.decode_jpeg(image_data)\n",
        "    poor_images_data.append(image_data)\n",
        "\n",
        "for image_path in enhanced_images:\n",
        "    image_data = tf.io.read_file(image_path)\n",
        "    image_data = tf.image.decode_jpeg(image_data)\n",
        "    enhanced_images_data.append(image_data)\n",
        "\n",
        "# Define the generator model\n",
        "generator = keras.Sequential([\n",
        "  layers.Dense(256, input_shape=(100,)),\n",
        "  layers.LeakyReLU(alpha=0.2),\n",
        "  layers.Dense(512),\n",
        "  layers.LeakyReLU(alpha=0.2),\n",
        "  layers.Dense(1024),\n",
        "  layers.LeakyReLU(alpha=0.2),\n",
        "  layers.Dense(2048),\n",
        "  layers.LeakyReLU(alpha=0.2),\n",
        "  layers.Dense(4096, activation='tanh')\n",
        "])\n",
        "\n",
        "# Define the discriminator model\n",
        "discriminator = keras.Sequential([\n",
        "  layers.Dense(4096, input_shape=(4096,)),\n",
        "  layers.LeakyReLU(alpha=0.2),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Dense(2048),\n",
        "  layers.LeakyReLU(alpha=0.2),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Dense(1024),\n",
        "  layers.LeakyReLU(alpha=0.2),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Dense(512),\n",
        "  layers.LeakyReLU(alpha=0.2),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Dense(256),\n",
        "  layers.LeakyReLU(alpha=0.2),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Define the conditional GAN model\n",
        "cgan = keras.Sequential([\n",
        "  generator,\n",
        "  discriminator\n",
        "])\n",
        "\n",
        "# Compile the cgan model\n",
        "cgan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5))\n",
        "\n",
        "# Train the cgan model\n",
        "cgan.fit(poor_images_data, enhanced_images_data, epochs=100, batch_size=32)\n",
        "\n",
        "# Evaluate the cgan model\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "generated_images = generator.predict(poor_images)\n",
        "mse_value = mse(generated_images, enhanced_images).numpy()\n",
        "\n",
        "print(\"MSE value:\", mse_value)\n"
      ],
      "metadata": {
        "id": "22-Wk_nPOjRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uPkuLpSax2lW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}